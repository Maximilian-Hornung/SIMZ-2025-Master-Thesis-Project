---
title: "Master Thesis Data Analysis"
format: pdf
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
# Load Libraries ####

library(tidyverse)
library(igraph)
library(ggraph)
library(cld2) #for text classification
library(gt)
library(glue)

# Load Custom Functions ####


cross_border_density <- function(g, Bilinguals.include = FALSE){
  
if (Bilinguals.include == FALSE) {
## Calculate existing cross-border ties between two groups
lang_1 <- V(g)[bilingual == "Russian-speaker"]$name
} else{
  lang_1 <- V(g)[bilingual %in% c("Russian-speaker","Bilingual")]$name  #if bilinguals included 
}

lang_2 <- V(g)[bilingual == "German-speaker"]$name


#Existing cross border ties between German and Russian speaker 
n_existing_cross_border_ties <- length(E(g)[lang_1 %--% lang_2])

## Calculate Total Possible Cross-Border Ties
n_nodes_lang_1<- length(lang_1)
n_nodes_lang_2 <- length(lang_2)
n_possible_cross_border_ties <-  n_nodes_lang_1*n_nodes_lang_2

cross_border_density <- n_existing_cross_border_ties / n_possible_cross_border_ties

cat("Cross-Border Density:", cross_border_density, "\n")

return(cross_border_density)
}

```

```{r load data}
# set wd
setwd("C:/Users/hornu/OneDrive/Master Social Scientific Data Analysis/Courses/SIMZ-2025 - Master Thesis Course/20250206 Spring Thesis Work/VK Network Data")

# load data
ego_network <- readRDS("ego_network_id850793471.rds")

```

```{r}

get_igraph <-  function(ego_network, simplify = TRUE) {  # create an i graph pbject with node attr

#create edge list
ego_id <- ego_network$from[1]  # Define ego ID
data_collection_time <- as.POSIXct(1742990000, origin = "1970-01-01", tz = "UTC") # Define the fixed data collection time 

edge_list_1.5_degree <- ego_network |> 
    filter(from != ego_id) |>  
    #filter(is.na(deactivated)) |>  
    select(from, to) |> 
    filter(!is.na(from) & !is.na(to) & from != to) |>  
    distinct()

filtenode_attr <- ego_network |> 
 # filter(is.na(deactivated)) |> 
  filter(from != ego_id) |> 
  distinct(to, .keep_all = TRUE)  # Keeps only the first occurrence of each unique 'to'


#extract string with German and Russian cities
German_cities <-  ego_network  |> 
 filter(country.title == "Germany" & city.title != is.na(city.title)) |>
 group_by(city.title) |> 
 summarise(number = n()) |> 
 pull(city.title)

Russian_cities <-  ego_network  |> 
 filter(country.title == "Russia" & city.title != is.na(city.title)) |>
 group_by(city.title) |> 
 summarise(number = n()) |> 
 pull(city.title)



  
#language labels
node_attr_new <- filtenode_attr |> 
  mutate(status_lang = detect_language(status), 
         interests_lang = detect_language(interests),
         quotes_lang = detect_language(quotes),
         about_lang = detect_language(about),
         activities_lang = detect_language(activities),
         home_town_lang = detect_language(home_town),
         personal_religion_lang = detect_language(personal.religion),
         personal_inspired_by_lang = detect_language(personal.inspired_by),
         education_form_lang = detect_language(education_form),
         education_status_lang = detect_language(education_status)) |> 
  mutate(across(ends_with("_lang"), ~ ifelse(. == "en", NA, .)))


#label user's language repertoire
node_attr_new <- node_attr_new |> 
  rowwise() |>  
  mutate( country = ifelse(is.na(country.title), "Unknown", country.title), 
          last_seen_hours = as.numeric(difftime(data_collection_time, 
                                               as.POSIXct(last_seen.time, origin="1970-01-01", tz = "UTC"), 
                                               units="hours")),          
          bilingual = case_when(
             any(c_across(starts_with("Language")) == "Deutsch", na.rm = TRUE) & 
             any(c_across(starts_with("Language")) == "Русский", na.rm = TRUE) ~ "Bilingual",
             
             (country.title == "Russia" | city.title %in% Russian_cities) & 
             any(c_across(status_lang:education_status_lang) == "de", na.rm = TRUE) ~ "Bilingual", 
             
             (country == "Germany" | city.title %in% German_cities) & 
             any(c_across(status_lang:education_status_lang) == "ru", na.rm = TRUE) ~ "Bilingual", 
             
             (country.title == "Germany" | city.title %in% German_cities | status_lang == "de" ) ~ "German-speaker",
             (country.title == "Russia" | city.title %in% Russian_cities | status_lang == "ru") ~ "Russian-speaker",
            
             TRUE ~ "Unknown")) |> 
  ungroup() 

    

# Create the graph from the adjacency matrix
g <- graph_from_data_frame(edge_list_1.5_degree, directed = FALSE)

# assign node attributes
V(g)$bilingual <- node_attr_new[match(V(g)$name,node_attr_new$to),]$bilingual
V(g)$last_seen_hours <- node_attr_new[match(V(g)$name,node_attr_new$to),]$last_seen_hours
betweenness_centrality <- igraph::betweenness(g, directed = FALSE,  weights = NULL,  normalized = TRUE)
V(g)$betweenness_centrality <- betweenness_centrality

if(simplify == T){
g <- simplify(
  g,
  remove.multiple = TRUE,
  remove.loops = TRUE,
  edge.attr.comb = igraph_opt("edge.attr.comb")
)

}

graph_list <- list("igraph" = g, "node_attr_df" = node_attr_new)

return(graph_list )


}


cross_border_density <- function(g, Bilinguals.include = FALSE){
  
if (Bilinguals.include == FALSE) {
## Calculate existing cross-border ties between two groups
lang_1 <- V(g)[bilingual == "Russian-speaker"]$name
} else{
  lang_1 <- V(g)[bilingual %in% c("Russian-speaker","Bilingual")]$name  #if bilinguals included 
}

lang_2 <- V(g)[bilingual == "German-speaker"]$name


#Existing cross border ties between German and Russian speaker 
n_existing_cross_border_ties <- length(E(g)[lang_1 %--% lang_2])

## Calculate Total Possible Cross-Border Ties
n_nodes_lang_1<- length(lang_1)
n_nodes_lang_2 <- length(lang_2)
n_possible_cross_border_ties <-  n_nodes_lang_1*n_nodes_lang_2

cross_border_density <- n_existing_cross_border_ties / n_possible_cross_border_ties

cat("Cross-Border Density:", cross_border_density, "\n")

return(cross_border_density)
}

```

```{r}
#visualize graph

graph_list <- get_igraph(ego_network = ego_network)
g <- graph_list[["igraph"]]
node_attr <- graph_list[["node_attr_df"]]


set.seed(126)
ggraph(g, layout = 'fr') +
  geom_edge_link() +
  geom_node_point(aes(color = factor(V(g)$bilingual), size = betweenness_centrality)) +
  scale_color_manual(values = c("green", "blue", "red", "grey"),
                     name = "Language Repertoire",   # Legend title
                     #labels = c("Group 1", "Group 2", "Group 3", "Group 4")
                     ) +  
  scale_size_continuous(name = "Betweenness Centrality", range = c(1, 5)) +  # Adjust size range
  theme_graph(background = 'white') +
  annotate("text", x = Inf, y = -Inf, label = "Collected with author's VK API Data Collection Tool and visualized with GGraph (´fr´ layout)", 
           hjust = 1, vjust = -1, size = 3, color = "black", fontface = "italic")
```

```{r components}

# Number of strongly connected components
scc <- igraph::components(g)
num_scc <- scc$no

no_max_scc <- max(scc$csize) # largest one
no_min_scc <- min(scc$csize) # smallest one

scc$csize[scc$csize > 1] # only components that have more than 1 member

# Get largest connected component
largest_component <- which.max(scc$csize)  

# Create a subgraph containing only the largest connected component
largest_scc <- induced_subgraph(g, which(scc$membership == largest_component))

cat(glue("For the Language-core network, we observe {num_scc} connected components, of which the largest one contains {no_max_scc} nodes, and the smallest one {no_min_scc}."))

```

```{r descriptives}
library(gt)

# Create a data frame with network descriptives
network_descriptives <- data.frame(
  Metric = c("Number of Nodes", "Number of Edges", "Overall Density",  "Cross-Border Density",
             "Average Degree", "Standard Deviation Degree", "Transitivity", "Average Path-Length"), 
  Value = round(c(
    vcount(g), # count nodes
    ecount(g), # count edges
    igraph::edge_density(g), # overall density for the weakly connected component
    cross_border_density(g), # cross-border density between Russia and German speaker excluding Bilinguals
    mean(igraph::degree(g)),  # mean degree
    sd(igraph::degree(g)),    # standard deviation of degree
    igraph::transitivity(g),  # transitivity
    igraph::mean_distance(g, directed = FALSE)  # average path length
  ), 2) # round to two decimal places
)

# Create a gt summary table
network_descriptives %>%
  gt() #%>%
  #tab_header( title = "Descriptive Statistics of the Network")

```

```{r ERGM}
library(sna)
library(ergm)
library(igraph)
library(network)


# Convert biggest component igraph to edgelist
edge_list <- as_edgelist(largest_scc)

# Convert edgelist to sna network
g_sna <- network(edge_list, directed = FALSE, loops = FALSE)


# Assign bilingual attribute using the correct matching approach
g_sna %v% "bilingual" <- node_attr$bilingual[match(network.vertex.names(g_sna), node_attr$to)]

g_sna %v% "sex" <- node_attr$sex[match(network.vertex.names(g_sna), node_attr$to)]

g_sna %v% "last_online" <- node_attr$last_seen_hours[match(network.vertex.names(g_sna), node_attr$to)]

# Compute betweenness centrality and assign it as a node attribute
betweenness_centrality <- betweenness(g_sna)
g_sna %v% "betweenness" <- betweenness_centrality

# Compute degree centrality and assign it as a node attribute
degree_centrality <- degree(g_sna)
g_sna %v% "degree" <- degree_centrality
```

```{r ERGM}
# Hypothesis 1 ('language homophily')
# ^^^^^^^^^^^^^^^
# users form more mutual friendships when
# they have the same language attribute

# Hypothesis 2 ('cross-border bridging')
# ^^^^^^^^^^^^^^^
# bilingual users form mutual friendship less based on 
# language preferences than monolingual users (in-significant or lower effect size 
# compared to monolingual combination).

# Hypothesis 3 ('Interaction: betweeness and bilinguals ')
# ^^^^^^^^^^^^
# do bilingual users with high betweeness centrality form 
# more ties than monolinguals with similar betweeness centrality

# Hypothesis 4 ('preferential attachment') / Controlling for Network self organization
# ^^^^^^^^^^^^
# users form mutual friendship based on whether
# others also have mutual friendships with them.

# Hypothesis 5 ('transitive closure') / Controlling for Network self organization
# ^^^^^^^^^^^^
# Users from friendships directly when their friends
# are already mutual friends.



#  attribute-based model
mod_a <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control 
      #nodecov("last_online") + 
      nodecov("degree"),
             eval.loglik = T,
             control = control.ergm(seed = 210615))

 summary(mod_a)
# 
# plot(gof(mod_a ))



# triad closure (TC) model
mod_b<- ergm(
  g_sna ~ edges + 
      #twopath() +
      gwesp(0.4, fixed=TRUE))

 summary(mod_b)
# mcmc.diagnostics(mod_b)


# full model
mod_c<- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      #nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control 
     # nodecov("last_online") + 
      nodecov("degree") +
     # twopath() +
    altkstar(0.5, fixed = T) +
    gwdegree(0.2, fixed=TRUE) +
      gwesp(0.8, fixed=TRUE),  #the higher the better for my network
             eval.loglik = T,
             control = control.ergm(seed = 210615))


summary(mod_c)
mcmc.diagnostics(mod_c)
plot(gof(mod_c))

#hierarchical models
#baesian



# questions: 
# should I keep all connected components or just the biggest on when estimating an ergm?
# why doeas twopath not work? -> new modelling strategy?
# new modelling strategy has bad gof, what to do? Or can I ignore it? 
# attribute-specific GWESP statistics?




# model with all specifications

fit_all <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   
      nodemix("bilingual") +  
      nodecov("betweenness") + 
      nodecov("last_online") + 
      nodecov("degree") +
      #twopath() +	 # for stabilisation of model*
      gwdegree(0.2, fixed=TRUE) +   # Helps control degree distribution
      gwesp(0.4, fixed=TRUE) +   # Captures transitivity (clustering) # try interaction term with nodemix
      altkstar(0.5, fixed = T), 
  control = control.ergm(
      seed = 123,
      #MCMC.samplesize = 10000,  
      # MCMC.burnin = 5000,       
      # MCMC.interval = 2000      
  )
)


plot(gof(fit_all))

summary(fit_all)

#tweeting across hashtags: overlapping users ans the importance of language, topic and politics 
```

```{r ERGM}
# full model + preferential attachment
mod_d<- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control 
      nodecov("last_online") + 
      nodecov("degree") +
      #twopath() +
      gwdegree(0.2, fixed=TRUE) +   # Helps control degree distribution
      gwesp(0.4, fixed=TRUE),  #the higher the better for my network
             eval.loglik = T,
             control = control.ergm(seed = 210615))



# questions: 
# should I keep all connected components or just the biggest on when estimating an ergm?
# why doeas twopath not work? -> new modelling strategy?
# new modelling strategy has bad gof, what to do? Or can I ignore it? 
# attribute-specific GWESP statistics?



summary(mod_b_1_1)
summary(mod_b_1)

plot(gof(mod_b ))



# transitive closure  and preferential attachment tendencies
mod_c <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control 
      nodecov("last_online") + 
      nodecov("degree") +
      #twopath() +
      gwesp(0.4, fixed=TRUE) + 
      altkstar(0.3, fixed = T),
             eval.loglik = T,
             control = control.ergm(seed = 210615))


summary(mod_c)
summary(mod_f)

#full model

mod_c <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   
      nodemix("bilingual") +  
      nodecov("betweenness") + 
      nodecov("last_online") + 
      twopath() +	 # for stabilisation of model*
      #gwdegree(0.2, fixed=TRUE) +   # Helps control degree distribution
      gwesp(0.2, fixed=TRUE),   # Captures transitivity (clustering)
 # control = control.ergm(
     # seed = 123,
      #MCMC.samplesize = 10000,  
      # MCMC.burnin = 5000,       
      # MCMC.interval = 2000      
 # )
)



summary(mod_c)







plot(gof(mod_a))


fit_new <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control 
      nodecov("last_online") + 
      nodecov("degree") +
      #twopath() +	 # for stabilisation of model*
      gwdegree(0.5, fixed=TRUE) +   # Hypothesis 4 / Control
	    gwesp(0.6, fixed=TRUE),        # Hypothesis 5 / Control
             eval.loglik = T,
             control = control.ergm(seed = 210615,
                                    MCMC.burnin = 50000,
                                    MCMC.samplesize = 7000,
                                    MCMC.interval = 2500,
                                    parallel = 0))

summary(g_sna)

fit_new_1 <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   
      nodemix("bilingual") +  
      nodecov("betweenness") + 
      nodecov("last_online") + 
      #twopath() +	 # for stabilisation of model*
      gwdegree(0.2, fixed=TRUE) +   # Helps control degree distribution
      gwesp(0.4, fixed=TRUE),   # Captures transitivity (clustering)
      #altkstar(0.5, fixed = T), 
  control = control.ergm(
      seed = 123,
      #MCMC.samplesize = 10000,  
      # MCMC.burnin = 5000,       
      # MCMC.interval = 2000      
  )
)

kstar(1) 

summary(fit_new_1 )

localtriangle(x)
kstar


altkstar(1)


fit_new <- ergm(
  g_sna ~ edges +  altkstar(0.5, fixed = T) + degree(0.5))

plot(gof(fit_new))
summary(g_sna)


summary(fit_new)
gof <- gof(fit_new_1)
plot(gof)

mcmc.diagnostics(fit_new, center=T)
```

```{r ERGM}
length(node_attr_new |> 
  filter(is.na(bdate)))

node_attr_new  |> 
  count(bilingual)


node_attr_new |> 
  filter(to == "96164") |> 
  select(bilingual, status_lang)


x <- node_attr_new |> 
  filter(bilingual == "Russian-speaker") |> 
  select(status_lang:education_status_lang)

colnames(node_attr_new)
```

```{r}
# Create the graph from the adjacency matrix
g <- graph_from_data_frame(edge_list_1.5_degree, directed = FALSE)

# assign node attributes
V(g)$bilingual <- node_attr_new[match(V(g)$name,node_attr_new$to),]$bilingual
V(g)$last_seen_hours <- node_attr_new[match(V(g)$name,node_attr_new$to),]$last_seen_hours
betweenness_centrality <- igraph::betweenness(g, directed = FALSE,  weights = NULL,  normalized = TRUE)
V(g)$betweenness_centrality <- betweenness_centrality

if(simplify == T){
g <- simplify(
  g,
  remove.multiple = TRUE,
  remove.loops = TRUE,
  edge.attr.comb = igraph_opt("edge.attr.comb")
)

}


set.seed(126)

ggraph(g, layout = 'fr') +
  geom_edge_link() +
  geom_node_point(aes(color = factor(V(g)$bilingual), size = betweenness_centrality)) +
  scale_color_manual(values = c("green", "blue", "red", "grey"),
                     name = "Language Repertoire",   # Legend title
                     #labels = c("Group 1", "Group 2", "Group 3", "Group 4")
                     ) +  
  scale_size_continuous(name = "Betweenness Centrality", range = c(1, 5)) +  # Adjust size range
  theme_graph(background = 'white') +
  annotate("text", x = Inf, y = -Inf, label = "Collected with author's VK API Data Collection Tool and visualized with GGraph (´fr´ layout)", 
           hjust = 1, vjust = -1, size = 3, color = "black", fontface = "italic")


```

```{r}
cross_border_density <- function(g, Bilinguals.include = FALSE){
  
if (Bilinguals.include == FALSE) {
## Calculate existing cross-border ties between two groups
lang_1 <- V(g)[bilingual == "Russian-speaker"]$name
} else{
  lang_1 <- V(g)[bilingual %in% c("Russian-speaker","Bilingual")]$name  #if bilinguals included 
}

lang_2 <- V(g)[bilingual == "German-speaker"]$name


#Existing cross border ties between German and Russian speaker 
n_existing_cross_border_ties <- length(E(g)[lang_1 %--% lang_2])

## Calculate Total Possible Cross-Border Ties
n_nodes_lang_1<- length(lang_1)
n_nodes_lang_2 <- length(lang_2)
n_possible_cross_border_ties <-  n_nodes_lang_1*n_nodes_lang_2

cross_border_density <- n_existing_cross_border_ties / n_possible_cross_border_ties

cat("Cross-Border Density:", cross_border_density, "\n")

return(cross_border_density)
}

cross_border_density(g)

```

```{r}
library(gt)

# Create a data frame with network descriptives
network_descriptives <- data.frame(
  Metric = c("Number of Nodes", "Number of Edges", "Overall Density",  "Cross-Border Density",
             "Average Degree", "Standard Deviation Degree", "Transitivity", "Average Path-Length"), 
  Value = round(c(
    vcount(g), # count nodes
    ecount(g), # count edges
    igraph::edge_density(g), # overall density for the weakly connected component
    cross_border_density(g), # cross-border density between Russia and German speaker excluding Bilinguals
    mean(igraph::degree(g)),  # mean degree
    sd(igraph::degree(g)),    # standard deviation of degree
    igraph::transitivity(g),  # transitivity
    igraph::mean_distance(g, directed = FALSE)  # average path length
  ), 2) # round to two decimal places
)

# Create a gt summary table
network_descriptives %>%
  gt() #%>%
  #tab_header( title = "Descriptive Statistics of the Network")

```

```{r descriptives 1}
# First basic descriptives: node count, edge count, directed?

## count nodes
length(V(g))
vcount(g)

# count edges
length(E(g)) 
ecount(g)

# directed?
is_directed(g)
```

```{r descriptives 2}

# Average degree
avg_degree <- mean(igraph::degree(g))


# Standard deviations
sd(igraph::degree(g))


# Range
range(igraph::degree(g))


# Make the graph symmetric (convert to an undirected graph)
#uG_eu <- as.undirected(G_eu, mode = "collapse")

# Average degree for the symmetric graph
avg_degree_symmetric <- mean(degree(g))
cat("After making the network symmetric, the average degree is:", 
    round(avg_degree_symmetric, 2), "\n")

```

## Density, reciprocity and degree measures.

```{r descriptives 3}

# Density
igraph::edge_density(g) # you can also report it as a percentage, density is sensitive to size

# Transitivity (= clustering coefficient)
# Captures triangles; how many of existing triads (e.g. relationships) are actually closed
igraph::transitivity(g)
# can also be calculated at the node-level

# cross-border density


cross_border_density <- function(g){
  
## Calculate existing cross-border ties between two groups
Russian_speaker <- V(g)[bilingual == "Russian-speaker"]$name

German_speaker <- V(g)[bilingual == "German-speaker"]$name

#Existing cross border ties between German and Russian speaker 
n_existing_cross_border_ties <- length(E(g)[Russian_speaker %--% German_speaker])


## Calculate Total Possible Cross-Border Ties
n_nodes_Russian_speaker <- length(Russian_speaker)
n_nodes_German_speaker <- length(German_speaker)
n_possible_cross_border_ties <-  n_nodes_Russian_speaker*n_nodes_German_speaker 

cross_border_density <- n_existing_cross_border_ties / n_possible_cross_border_ties

cat("Cross-Border Density:", cross_border_density, "\n")

return(cross_border_density)
}

cross_border_density(g)

```

```{r descriptives 4}
library(glue)
# Number of strongly connected components
scc <- igraph::components(g)
num_scc <- scc$no

no_max_scc <- max(scc$csize) # largest one
no_min_scc <- min(scc$csize) # smallest one

scc$csize[scc$csize > 1] # only components that have more than 1 member

cat(glue("For the EU-core network, we observe {num_scc} connected components, of which the largest one contains {no_max_scc} nodes, and the smallest one {no_min_scc}."))

```

```{r degree of separation }
# Get largest connected component
largest_component <- which.max(scc$csize)  

# Create a subgraph containing only the largest connected component
largest_scc <- induced_subgraph(g, which(scc$membership == largest_component))

avg_path_length <- mean_distance(largest_scc, directed = FALSE, unconnected = FALSE)
cat(glue("Our network has {round(avg_path_length, 2)} degrees of separation."))
```

```{r closeness centrality}

cc <- igraph::closeness(largest_scc) # here we get NANs for those nodes which are isolates

hist(cc_igraph,
     main = "Histogram of Closeness Centrality values", 
     xlab = "Closeness Centrality", 
     ylab = "Count", 
     breaks = 50,
     border = "white")
```

```{r betweenness centrality}
betweenness_centrality <- igraph::betweenness(g, directed = FALSE,  weights = NULL,  normalized = TRUE)

V(g)$betweenness_centrality <- betweenness_centrality


hist(betweenness_centrality, 
     breaks = 50, 
     main = "Histogram of Betweenness Centrality values", 
     xlab = "Betweenness Centrality", 
     ylab = "Count", 
     border = "white")

#include average path lenght as how information travels 
#include E-I index 
#include cross-border density
#number of bilingual users and monolingual users based on connectivtiy 
```

```{r}
library(sna)
library(ergm)
library(igraph)
library(network)


# Convert biggest component igraph to edgelist
edge_list <- as_edgelist(largest_scc)

# Convert edgelist to sna network
g_sna <- network(edge_list, directed = FALSE, loops = FALSE)


# Assign bilingual attribute using the correct matching approach
g_sna %v% "bilingual" <- node_attr_new$bilingual[match(network.vertex.names(g_sna), node_attr_new$to)]

g_sna %v% "sex" <- node_attr_new$sex[match(network.vertex.names(g_sna), node_attr_new$to)]


# Calculate betweenness centrality
betweenness_centrality <- betweenness(g_sna)

# Assign betweenness centrality as a node attribute

g_sna %v% "betweenness" <- betweenness_centrality



# Hypothesis 1 ('language homophily')
# ^^^^^^^^^^^^^^^
# users form more mutual friendships when
# they have the same language attribute

# Hypothesis 2 ('cross-border bridging')
# ^^^^^^^^^^^^^^^
# bilingual users form mutual friendship less based on 
# language preferences than monolingual users (in-significant or lower effect size 
# compared to monolingual combination).

# Hypothesis 3 ('Interaction: betweeness and bilinguals ')
# ^^^^^^^^^^^^
# do bilingual users with high betweeness centrality form 
# more ties than monolinguals with similar betweeness centrality

# Hypothesis 4 ('preferential attachment') / Controlling for Network self organization
# ^^^^^^^^^^^^
# users form mutual friendship based on whether
# others also have mutual friendships with them.

# Hypothesis 5 ('transitive closure') / Controlling for Network self organization
# ^^^^^^^^^^^^
# Users from friendships directly when their friends
# are already mutual friends.


fit_new <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control
      twopath() +	 # for stabilisation of model*
      gwdegree(0.5, fixed=TRUE) +   # Hypothesis 4 / Control
	    gwesp(0.8, fixed=TRUE),        # Hypothesis 5 / Control
             eval.loglik = T,
             control = control.ergm(seed = 210615,
                                    MCMC.burnin = 50000,
                                    MCMC.samplesize = 7000,
                                    MCMC.interval = 2500,
                                    parallel = 0))




fit <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control
      twopath +				            	# for stabilisation of model*
      gwdegree(0.7, fixed=TRUE) +   # Hypothesis 4 / Control
	    gwesp(0.5, fixed=TRUE),        # Hypothesis 5 / Control
      control = control.ergm(MCMLE.density.guard = 50)
  )
# * the twopath effect can also be interpreted as a test
#   for the hypothesis
#   "Form user friendship with user who themselves
#    form friendships with others?"



summary(fit)

test_model <- ergm(g_sna ~ edges +
                     #nodemix("bilingual") + 
                     gwesp(0.25,fixed=T)
                     degree(1), 
            control=snctrl(MCMC.interval = 10000),
            verbose=T)





fit_new <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control
      twopath() +	 # for stabilisation of model*
      gwdegree(0.5, fixed=TRUE) +   # Hypothesis 4 / Control
	    gwesp(0.8, fixed=TRUE),        # Hypothesis 5 / Control
             eval.loglik = T,
             control = control.ergm(seed = 210615,
                                    MCMC.burnin = 50000,
                                    MCMC.samplesize = 7000,
                                    MCMC.interval = 2500,
                                    parallel = 0))


summary(fit_new)


summary(g_sna ~ twopath)
test_model <- ergm(g_sna ~ edges +
                     nodemix("bilingual") + 
                     gwesp(0.1,fixed=T),
            control=snctrl(MCMC.interval = 10000),
            verbose=T)






mcmc.diagnostics(fit_new, center=F)

summary(test_model)


plot(gof(fit_new))


m7 = ergm(g_sna ~ edges + nodemix("bilingual") + 
              gwesp(decay = .5, fixed = TRUE) + 
              gwdegree(decay = 1, fixed = TRUE),
  control = control.ergm(
    MCMC.samplesize = 1e+5, 
    MCMC.burnin = 1e+6, 
    MCMC.interval = 1000, 
    seed = 567
  ))



test_model_simple <- ergm(g_sna ~ edges + twopath)


test_model <- ergm(g_sna ~ edges + 
                   nodemix("bilingual") + 
                   twopath + 
                   gwesp(0.5, fixed=TRUE),
                   control = control.ergm(MCMC.maxit = 5000))


summary(test_model_simple)

#ergm 

fit <- ergm(
  g_sna ~ edges + 
      nodematch("sex") +   # gender homophily / Control
      nodemix("bilingual") +  # Hypothesis 1 & #Hypothesis 2 
      nodecov("betweenness") + # preferential attachment based on user betweeness centrality / Control
      #nodecov("betweenness") * nodemix("bilingual") +   # Hypothesis 3
      twopath +				            	# for stabilisation of model*
      gwdegree(0.7, fixed=TRUE) +   # Hypothesis 4 / Control
	    gwesp(0.5, fixed=TRUE)        # Hypothesis 5 / Control
  )
# * the twopath effect can also be interpreted as a test
#   for the hypothesis
#   "Form user friendship with user who themselves
#    form friendships with others?"





summary(fit)


table(g %v% "bilingual")


```

```{r}
node_attr_new <- node_attr_new |> 
  rowwise() |>  # Ensures row-wise operations
  mutate(bilingual = case_when(
    # If all values are NA in language columns or only German language is detected,
    # OR if city.title is NA, but at least one language column indicates German
    (all(is.na(c_across(status_lang:education_status_lang))) | 
     all(c_across(status_lang:education_status_lang) == "de", na.rm = TRUE) | 
     all(c_across(starts_with("Language")) == "Deutsch", na.rm = TRUE)) & 
     country.title %in% c("Germany", "Austria", "Switzerland", "Luxembourg") ~ "German-speaker",

    is.na(country.title) & 
    (all(c_across(status_lang:education_status_lang) == "de", na.rm = TRUE) & 
     all(c_across(starts_with("Language")) == "Deutsch", na.rm = TRUE)) ~ "German-speaker",

    # If all values are NA or only Russian language is detected
    # OR if city.title is NA, but at least one language column indicates Russian
    (all(is.na(c_across(status_lang:education_status_lang))) | 
     all(c_across(status_lang:education_status_lang) == "ru", na.rm = TRUE) | 
     all(c_across(starts_with("Language")) == "Русский", na.rm = TRUE)) & 
     country.title %in% c("Russia", "Ukraine") ~ "Russian-speaker",

    is.na(country.title) & 
    (all(c_across(status_lang:education_status_lang) == "ru", na.rm = TRUE) & 
     all(c_across(starts_with("Language")) == "Русский", na.rm = TRUE)) ~ "Russian-speaker",

    # English-speaker logic
    (all(is.na(c_across(status_lang:education_status_lang))) | 
     all(c_across(status_lang:education_status_lang) == "en", na.rm = TRUE) | 
     all(c_across(starts_with("Language")) == "English", na.rm = TRUE)) & 
     country.title %in% c("USA", "United Kingdom") ~ "English-speaker",

    is.na(country.title) & 
    (all(c_across(status_lang:education_status_lang) == "en", na.rm = TRUE) & 
     all(c_across(starts_with("Language")) == "English", na.rm = TRUE)) ~ "English-speaker",
    
    # Unknown if all language and location values are NA
    all(is.na(c_across(c("status_lang", "education_status_lang", "Language1", "Language2", "Language3", "city.title")))) ~ "Unknown",

    # Default to bilingual for cases not covered by above conditions
    TRUE ~ "Bilingual"
  )) |>  
  ungroup()  # Removes rowwise grouping
```
